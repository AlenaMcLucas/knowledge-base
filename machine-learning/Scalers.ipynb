{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalers\n",
    "\n",
    "For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger that others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n",
    "In addition to aiding in convergence, scalers also handle outliers in different ways.\n",
    "\n",
    "Centering and scaling happen independently on each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scalar\n",
    "\n",
    "StandardScaler removes the mean and scales the data to unit variance. However, the outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values. StandardScaler therefore cannot guarantee balanced feature scales in the presence of outliers.\n",
    "\n",
    "$z = \\frac{x - u}{s}$\n",
    "\n",
    "where $u$ is the mean of the training samples and $s$ is the standard deviation of the training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Max Scaler\n",
    "\n",
    "MinMaxScaler rescales the data set such that all feature values are in the range [0, 1]. However, this scaling compress all inliers in a narrow range. Therefore, MinMaxScaler is very sensitive to the presence of outliers.\n",
    "\n",
    "$\\frac{x_i - min(x)}{max(x) - min(x)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Abs Scalar\n",
    "\n",
    "MaxAbsScaler differs from the previous scaler such that the absolute values are mapped in the range [0, 1]. On positive only data, this scaler behaves similarly to MinMaxScaler and therefore also suffers from the presence of large outliers.\n",
    "\n",
    "$\\frac{x_i}{max(abs(x))}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler (IQR)\n",
    "\n",
    "The centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar.\n",
    "\n",
    "$\\frac{x_i – median(x)}{p75(x) – p25(x)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PowerTransformer\n",
    "\n",
    "https://medium.com/@patricklcavins/using-scipys-powertransformer-3e2b792fd712\n",
    "\n",
    "PowerTransformer applies a power transformation to each feature to make the data more Gaussian-like. By default, PowerTransformer implements the Yeo-Johnson transform. The power transform finds the optimal scaling factor to stabilize variance and mimimize skewness through maximum likelihood estimation. By default, PowerTransformer also applies zero-mean, unit variance normalization to the transformed output.\n",
    "\n",
    "PowerTransformer, more specifically, can fix heteroskedasticity resulting from a variable's skewed distribution. A Probability Plot will sometimes reveal variance at the higher/lower end of the dependent variable. The PowerTransformer's objective is to obtain a normal distribution for that variable. This helps us not violate assumptions for Linear Regression, for example, that variables have a normal distribution and are homoskedastic.\n",
    "\n",
    "To decide whether or not to apply this transformation, check for a normal distribution. To automate this, kurtosis and skew can be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
